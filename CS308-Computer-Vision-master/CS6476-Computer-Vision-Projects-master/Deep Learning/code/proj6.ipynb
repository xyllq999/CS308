{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Deep Learning](https://www.cc.gatech.edu/~hays/compvision/proj6/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import student_code as sc\n",
    "from torchvision.models import alexnet\n",
    "\n",
    "data_path = osp.join('../data', '15SceneData')\n",
    "num_classes = 15\n",
    "\n",
    "# If you have a good Nvidia GPU with an appropriate environment, \n",
    "# try setting the use_GPU flag to True (the environment provided does\n",
    "# not support GPUs and we will not provide any support for GPU\n",
    "# computation in this project). Please note that \n",
    "# we will evaluate your implementations only using CPU mode so even if\n",
    "# you use a GPU, make sure your code runs in the CPU mode with the\n",
    "# environment we provided. \n",
    "use_GPU = False\n",
    "if use_GPU:\n",
    "    from utils_gpu import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a network in PyTorch, we need 4 components:\n",
    "1. **Dataset** - an object which can load the data and labels given an index.\n",
    "2. **Model** - an object that contains the network architecture definition.\n",
    "3. **Loss function** - a function that measures how far the network output is from the ground truth label.\n",
    "4. **Optimizer** - an object that optimizes the network parameters to reduce the loss value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project has two main parts. In Part 1, you will train a deep network from scratch. In Part 2, you will \"fine-tune\" a trained network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0. Warm up! Training a Deep Network from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seeds so that results will be reproducible\n",
    "set_seed(0, use_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not need to code anything for this part. You will simply run the code we provided, but we want you to report the result you got. This section will also familiarize you with the steps of training a deep network from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters.\n",
    "input_size = (64, 64)\n",
    "RGB = False  \n",
    "base_lr = 1e-2  # may try a smaller lr if not using batch norm\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create our datasets, by calling the create_datasets function from student_code. This function returns a separate dataset loader for each split of the dataset (training and testing/validation). Each dataloader is used to load the datasets after appling some pre-processing transforms. In Part 1, you will be asked to add a few more pre-processing transforms to the dataloaders by modifying this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pixel mean and stdev...\n",
      "Batch 0 / 30\n",
      "Batch 20 / 30\n",
      "Done, mean = \n",
      "[0.45579668]\n",
      "std = \n",
      "[0.23624939]\n",
      "Computing pixel mean and stdev...\n",
      "Batch 0 / 60\n",
      "Batch 20 / 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-53-0fd792495c87>\", line 2, in <module>\n",
      "    train_dataset, test_dataset = sc.create_datasets(data_path=data_path, input_size=input_size, rgb=RGB)\n",
      "  File \"/Users/mrisleyz/Desktop/CS6746/proj6/code/student_code.py\", line 48, in create_datasets\n",
      "    test_mean, test_std = utils.get_mean_std(test_data_path, input_size, rgb)\n",
      "  File \"/Users/mrisleyz/Desktop/CS6746/proj6/code/utils.py\", line 309, in get_mean_std\n",
      "    for idx, (data, labels) in enumerate(train_loader):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 314, in __next__\n",
      "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 314, in <listcomp>\n",
      "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/PIL/Image.py\", line 916, in convert\n",
      "    if \"transparency\" in self.info and \\\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2978, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1866, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1373, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1281, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1133, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1078, in format_exception_as_a_whole\n",
      "    frames = self.format_records(records, last_unique, recursion_repeat)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 818, in format_records\n",
      "    frames.append(self.format_record(*r))\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1007, in format_record\n",
      "    _line_format)))\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 385, in _format_traceback_lines\n",
      "    new_line, err = _line_format(line, 'str')\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/utils/PyColorize.py\", line 261, in format2\n",
      "    self(*atoken)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/utils/PyColorize.py\", line 318, in __call__\n",
      "    owrite('%s%s%s' % (color,toktext,colors.normal))\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/utils/ipstruct.py\", line 147, in __getattr__\n",
      "    result = self[key]\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 36385) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/inspect.py\", line 1459, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/inspect.py\", line 1421, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 177, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/tokenize.py\", line 456, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/tokenize.py\", line 425, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/tokenize.py\", line 383, in read_or_stop\n",
      "    return readline()\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 36238) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-53-0fd792495c87>\", line 2, in <module>\n",
      "    train_dataset, test_dataset = sc.create_datasets(data_path=data_path, input_size=input_size, rgb=RGB)\n",
      "  File \"/Users/mrisleyz/Desktop/CS6746/proj6/code/student_code.py\", line 48, in create_datasets\n",
      "    test_mean, test_std = utils.get_mean_std(test_data_path, input_size, rgb)\n",
      "  File \"/Users/mrisleyz/Desktop/CS6746/proj6/code/utils.py\", line 309, in get_mean_std\n",
      "    for idx, (data, labels) in enumerate(train_loader):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 314, in __next__\n",
      "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 314, in <listcomp>\n",
      "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/PIL/Image.py\", line 916, in convert\n",
      "    if \"transparency\" in self.info and \\\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2978, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1866, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1373, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1281, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1133, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1078, in format_exception_as_a_whole\n",
      "    frames = self.format_records(records, last_unique, recursion_repeat)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 818, in format_records\n",
      "    frames.append(self.format_record(*r))\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1007, in format_record\n",
      "    _line_format)))\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 385, in _format_traceback_lines\n",
      "    new_line, err = _line_format(line, 'str')\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/utils/PyColorize.py\", line 261, in format2\n",
      "    self(*atoken)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/utils/PyColorize.py\", line 318, in __call__\n",
      "    owrite('%s%s%s' % (color,toktext,colors.normal))\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/utils/ipstruct.py\", line 147, in __getattr__\n",
      "    result = self[key]\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 36385) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2926, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1866, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1373, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1281, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1144, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: Can't convert 'list' object to str implicitly\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2666, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "UnboundLocalError: local variable 'result' referenced before assignment\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/logging/__init__.py\", line 988, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 36339) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "Call stack:\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/asyncio/events.py\", line 127, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/mrisleyz/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    self.log.error(\"Exception in message handler:\", exc_info=True)\n",
      "Message: 'Exception in message handler:'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "# Create the training and testing datasets.\n",
    "train_dataset, test_dataset = sc.create_datasets(data_path=data_path, input_size=input_size, rgb=RGB)\n",
    "assert test_dataset.classes == train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create our network model using the SimpleNet class from student_code. The implementation provided in the SimpleNet class gives you a basic network. In Part 1, you will be asked to add a few more layers to this network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 15, kernel_size=(9, 9), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(15, 25, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Dropout(p=0.5)\n",
      "  )\n",
      "  (classifier): Conv2d(25, 15, kernel_size=(11, 11), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the network model.\n",
    "model = sc.SimpleNet(num_classes=num_classes, rgb=False, verbose=False)\n",
    "if use_GPU:\n",
    "    model = model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create the loss function and the optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the loss function.\n",
    "# see http://pytorch.org/docs/0.3.0/nn.html#loss-functions for a list of available loss functions\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer and a learning rate scheduler\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=base_lr, weight_decay=weight_decay, momentum=momentum)\n",
    "# Currently a simple step scheduler.\n",
    "# See http://pytorch.org/docs/0.3.0/optim.html#how-to-adjust-learning-rate for various LR schedulers\n",
    "# and how to use them\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we are ready to train our network! We will start a local server to see the training progress of our network. Open a new terminal and activate the environment for this project. Then run the following command: **python -m visdom.server**. This will start a local server. The terminal output should give out a link like: \"http://localhost:8097\". Open this link in your browser. After you run the following block, visit this link again, and you will be able to see graphs showing the progress of your training! If you do not see any graphs, select Part 1 on the top left bar where is says Environment (only select Part 1, do not check main or Part 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Experiment: part1\n",
      "checkpoint_file: None\n",
      "val_freq: 1\n",
      "resume_optim: True\n",
      "batch_size: 50\n",
      "experiment: part1\n",
      "do_val: True\n",
      "print_freq: 100\n",
      "shuffle: True\n",
      "num_workers: 4\n",
      "n_epochs: 100\n",
      "---------------------------------------\n",
      "part1 Epoch 0 / 100\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [15, 1, 9, 9], expected input[50, 3, 224, 224] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-44afdd0e76c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'experiment'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'part1'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbest_prec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best top-1 Accuracy = {:4.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_prec1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CS6746/proj6/code/utils.py\u001b[0m in \u001b[0;36mtrain_val\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m       \u001b[0;31m# TRAIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop1_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5_prec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       self.vis.line(X=np.asarray([epoch]), Y=np.asarray([loss]),\n\u001b[1;32m    236\u001b[0m         win=self.loss_win, name='train_loss', update='append', env=self.vis_env)\n",
      "\u001b[0;32m~/Desktop/CS6746/proj6/code/utils.py\u001b[0m in \u001b[0;36mstep_func\u001b[0;34m(self, train)\u001b[0m\n\u001b[1;32m    198\u001b[0m       kwargs = dict(target=target, loss_fn=self.loss_fn,\n\u001b[1;32m    199\u001b[0m         optim=self.optimizer, train=train)\n\u001b[0;32m--> 200\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_feedfwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0;31m# measure accuracy and calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CS6746/proj6/code/utils.py\u001b[0m in \u001b[0;36mstep_feedfwd\u001b[0;34m(data, model, target, loss_fn, optim, train)\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mdata_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CS6746/proj6/code/student_code.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/cs6476p6/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [15, 1, 9, 9], expected input[50, 3, 224, 224] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "# train the network!\n",
    "params = {'n_epochs': 100, 'batch_size': 50, 'experiment': 'part1'}\n",
    "trainer = Trainer(train_dataset, test_dataset, model, loss_function, optimizer, lr_scheduler, params)\n",
    "best_prec1 = trainer.train_val()\n",
    "print('Best top-1 Accuracy = {:4.3f}'.format(best_prec1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expect this code to take around 5 minutes on CPU or 3 minutes on GPU. Now you are ready to actually modify the functions we used to train our model. Before you move on, make sure to record the accuracy of your network from Part 0, and report it in your write up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Modifying the Dataloaders and the Simple Network create_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seeds so that results will be reproducible\n",
    "set_seed(0, use_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will modify the create_datasets function from student_code. You will add random left-right mirroring and normalization to the transformations applied to the training dataset. You will also add normalization to the transformations applied to the testing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pixel mean and stdev...\n",
      "Batch 0 / 30\n",
      "Batch 20 / 30\n",
      "Done, mean = \n",
      "[0.45579668]\n",
      "std = \n",
      "[0.23624939]\n",
      "Computing pixel mean and stdev...\n",
      "Batch 0 / 60\n",
      "Batch 20 / 60\n",
      "Batch 40 / 60\n",
      "Done, mean = \n",
      "[0.45517009]\n",
      "std = \n",
      "[0.2350788]\n"
     ]
    }
   ],
   "source": [
    "# Create the training and testing datasets.\n",
    "train_dataset, test_dataset = sc.create_datasets(data_path=data_path, input_size=input_size, rgb=RGB)\n",
    "assert test_dataset.classes == train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will modify SimpleNet by adding droppout, batch normalization, and additional convolution/maxpool/relu layers. You should achieve an accuracy of at least **50%**. Make sure your network passes this threshold--it is required for full credit on this section!\n",
    "\n",
    "You can also use the following two blocks to determine the stucture of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 15, kernel_size=(9, 9), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(15, 25, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Dropout(p=0.5)\n",
      "  )\n",
      "  (classifier): Conv2d(25, 15, kernel_size=(11, 11), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create the network model\n",
    "model = sc.SimpleNet(num_classes=num_classes, rgb=False, verbose=False)\n",
    "if use_GPU:\n",
    "    model = model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network output size is  torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "# Use this block to determine the kernel size of the conv2d layer in the classifier\n",
    "# first, set the kernel size of that conv2d layer to 1, and run this block\n",
    "# then, use that size of input to the classifier printed by this block to\n",
    "# go back and update the kernel size of the conv2d layer in the classifier\n",
    "# Finally, run this block again and verify that the network output size is a scalar\n",
    "# Don't forget to re-run the block above every time you update the SimpleNet class!\n",
    "from torch.autograd import Variable\n",
    "data, _ = train_dataset[0]\n",
    "s = data.size()\n",
    "data = Variable(data.view(1, *s))\n",
    "if use_GPU:\n",
    "    data = data.cuda()\n",
    "out = model(data)\n",
    "print('Network output size is ', out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create the loss function and the optimizer. You do not have to modify the custom_part1_trainer in student_code if you use the same loss_function, optimizer, scheduler and parameters (n_epoch, batch_size etc.) as provided in this notebook to hit the required threshold of 50% accuracy. If you changed any of these values, it is important that you modify this function in student_code since we will not be using the notebook you submit to evaluate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the trainer. You can modify custom_part1_trainer in\n",
    "# student_copy.py if you want to try different learning settings.\n",
    "custom_part1_trainer = sc.custom_part1_trainer(model)\n",
    "\n",
    "if custom_part1_trainer is None:\n",
    "    # Create the loss function.\n",
    "    # see http://pytorch.org/docs/0.3.0/nn.html#loss-functions for a list of available loss functions\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Create the optimizer and a learning rate scheduler.\n",
    "    optimizer = optim.SGD(params=model.parameters(), lr=base_lr, weight_decay=weight_decay, momentum=momentum)\n",
    "    # Currently a simple step scheduler, but you can get creative.\n",
    "    # See http://pytorch.org/docs/0.3.0/optim.html#how-to-adjust-learning-rate for various LR schedulers\n",
    "    # and how to use them\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1)\n",
    "\n",
    "    params = {'n_epochs': 100, 'batch_size': 50, 'experiment': 'part1'}\n",
    "    \n",
    "else:\n",
    "    if 'loss_function' in custom_part1_trainer:\n",
    "        loss_function = custom_part1_trainer['loss_function']\n",
    "    if 'optimizer' in custom_part1_trainer:\n",
    "        optimizer = custom_part1_trainer['optimizer']\n",
    "    if 'lr_scheduler' in custom_part1_trainer:\n",
    "        lr_scheduler = custom_part1_trainer['lr_scheduler']\n",
    "    if 'params' in custom_part1_trainer:\n",
    "        params = custom_part1_trainer['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to train our network! As before, we will start a local server to see the training progress of our network (if you server is already running, you should not start another one). Open a new terminal and activate the environment for this project. Then run the following command: **python -m visdom.server**. This will start a local server. The terminal output should give out a link like: \"http://localhost:8097\". Open this link in your browser. After you run the following block, visit this link again, and you will be able to see graphs showing the progress of your training! If you do not see any graphs, select Part 1 on the top left bar where is says Environment (only select Part 1, do not check main or Part 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Experiment: part1\n",
      "checkpoint_file: None\n",
      "val_freq: 1\n",
      "resume_optim: True\n",
      "batch_size: 50\n",
      "experiment: part1\n",
      "do_val: True\n",
      "print_freq: 100\n",
      "shuffle: True\n",
      "num_workers: 4\n",
      "n_epochs: 100\n",
      "---------------------------------------\n",
      "part1 Epoch 0 / 100\n",
      "train part1: batch 0/29, loss 3.342, top-1 accuracy 4.000, top-5 accuracy 28.000\n",
      "train part1: loss 3.807662\n",
      "val part1: batch 0/59, loss 6.875, top-1 accuracy 2.000, top-5 accuracy 36.000\n",
      "val part1: loss 4.959694\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 1 / 100\n",
      "train part1: batch 0/29, loss 3.507, top-1 accuracy 22.000, top-5 accuracy 64.000\n",
      "train part1: loss 3.051370\n",
      "val part1: batch 0/59, loss 2.859, top-1 accuracy 14.000, top-5 accuracy 64.000\n",
      "val part1: loss 2.490936\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 2 / 100\n",
      "train part1: batch 0/29, loss 2.180, top-1 accuracy 28.000, top-5 accuracy 76.000\n",
      "train part1: loss 2.024946\n",
      "val part1: batch 0/59, loss 2.430, top-1 accuracy 18.000, top-5 accuracy 64.000\n",
      "val part1: loss 1.862079\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 3 / 100\n",
      "train part1: batch 0/29, loss 1.730, top-1 accuracy 48.000, top-5 accuracy 86.000\n",
      "train part1: loss 1.690409\n",
      "val part1: batch 0/59, loss 1.818, top-1 accuracy 32.000, top-5 accuracy 88.000\n",
      "val part1: loss 1.801313\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 4 / 100\n",
      "train part1: batch 0/29, loss 1.677, top-1 accuracy 46.000, top-5 accuracy 80.000\n",
      "train part1: loss 1.592959\n",
      "val part1: batch 0/59, loss 1.915, top-1 accuracy 28.000, top-5 accuracy 84.000\n",
      "val part1: loss 1.848622\n",
      "Checkpoint saved\n",
      "part1 Epoch 5 / 100\n",
      "train part1: batch 0/29, loss 1.595, top-1 accuracy 42.000, top-5 accuracy 86.000\n",
      "train part1: loss 1.573016\n",
      "val part1: batch 0/59, loss 2.355, top-1 accuracy 18.000, top-5 accuracy 72.000\n",
      "val part1: loss 1.748015\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 6 / 100\n",
      "train part1: batch 0/29, loss 1.654, top-1 accuracy 56.000, top-5 accuracy 82.000\n",
      "train part1: loss 1.521954\n",
      "val part1: batch 0/59, loss 2.475, top-1 accuracy 18.000, top-5 accuracy 70.000\n",
      "val part1: loss 1.926742\n",
      "Checkpoint saved\n",
      "part1 Epoch 7 / 100\n",
      "train part1: batch 0/29, loss 1.383, top-1 accuracy 58.000, top-5 accuracy 92.000\n",
      "train part1: loss 1.492114\n",
      "val part1: batch 0/59, loss 1.979, top-1 accuracy 28.000, top-5 accuracy 86.000\n",
      "val part1: loss 1.772346\n",
      "Checkpoint saved\n",
      "part1 Epoch 8 / 100\n",
      "train part1: batch 0/29, loss 1.516, top-1 accuracy 54.000, top-5 accuracy 92.000\n",
      "train part1: loss 1.457448\n",
      "val part1: batch 0/59, loss 2.439, top-1 accuracy 34.000, top-5 accuracy 68.000\n",
      "val part1: loss 1.847399\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 9 / 100\n",
      "train part1: batch 0/29, loss 1.559, top-1 accuracy 44.000, top-5 accuracy 92.000\n",
      "train part1: loss 1.386514\n",
      "val part1: batch 0/59, loss 1.861, top-1 accuracy 40.000, top-5 accuracy 84.000\n",
      "val part1: loss 1.639998\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 10 / 100\n",
      "train part1: batch 0/29, loss 1.055, top-1 accuracy 72.000, top-5 accuracy 98.000\n",
      "train part1: loss 1.318552\n",
      "val part1: batch 0/59, loss 2.207, top-1 accuracy 16.000, top-5 accuracy 82.000\n",
      "val part1: loss 1.786638\n",
      "Checkpoint saved\n",
      "part1 Epoch 11 / 100\n",
      "train part1: batch 0/29, loss 1.403, top-1 accuracy 52.000, top-5 accuracy 90.000\n",
      "train part1: loss 1.281342\n",
      "val part1: batch 0/59, loss 2.326, top-1 accuracy 14.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.642159\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 12 / 100\n",
      "train part1: batch 0/29, loss 1.176, top-1 accuracy 66.000, top-5 accuracy 96.000\n",
      "train part1: loss 1.263238\n",
      "val part1: batch 0/59, loss 2.396, top-1 accuracy 20.000, top-5 accuracy 74.000\n",
      "val part1: loss 1.829800\n",
      "Checkpoint saved\n",
      "part1 Epoch 13 / 100\n",
      "train part1: batch 0/29, loss 1.253, top-1 accuracy 60.000, top-5 accuracy 88.000\n",
      "train part1: loss 1.278944\n",
      "val part1: batch 0/59, loss 2.094, top-1 accuracy 28.000, top-5 accuracy 80.000\n",
      "val part1: loss 1.647017\n",
      "Checkpoint saved\n",
      "part1 Epoch 14 / 100\n",
      "train part1: batch 0/29, loss 1.085, top-1 accuracy 58.000, top-5 accuracy 98.000\n",
      "train part1: loss 1.228292\n",
      "val part1: batch 0/59, loss 1.416, top-1 accuracy 44.000, top-5 accuracy 92.000\n",
      "val part1: loss 1.742327\n",
      "Checkpoint saved\n",
      "part1 Epoch 15 / 100\n",
      "train part1: batch 0/29, loss 1.056, top-1 accuracy 62.000, top-5 accuracy 98.000\n",
      "train part1: loss 1.242086\n",
      "val part1: batch 0/59, loss 2.210, top-1 accuracy 32.000, top-5 accuracy 80.000\n",
      "val part1: loss 1.800349\n",
      "Checkpoint saved\n",
      "part1 Epoch 16 / 100\n",
      "train part1: batch 0/29, loss 1.114, top-1 accuracy 62.000, top-5 accuracy 94.000\n",
      "train part1: loss 1.114690\n",
      "val part1: batch 0/59, loss 2.271, top-1 accuracy 32.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.619506\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 17 / 100\n",
      "train part1: batch 0/29, loss 1.334, top-1 accuracy 58.000, top-5 accuracy 96.000\n",
      "train part1: loss 1.094714\n",
      "val part1: batch 0/59, loss 2.176, top-1 accuracy 28.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.764883\n",
      "Checkpoint saved\n",
      "part1 Epoch 18 / 100\n",
      "train part1: batch 0/29, loss 1.413, top-1 accuracy 64.000, top-5 accuracy 90.000\n",
      "train part1: loss 1.084679\n",
      "val part1: batch 0/59, loss 2.532, top-1 accuracy 16.000, top-5 accuracy 70.000\n",
      "val part1: loss 1.636517\n",
      "Checkpoint saved\n",
      "part1 Epoch 19 / 100\n",
      "train part1: batch 0/29, loss 0.706, top-1 accuracy 76.000, top-5 accuracy 100.000\n",
      "train part1: loss 1.038163\n",
      "val part1: batch 0/59, loss 2.357, top-1 accuracy 30.000, top-5 accuracy 72.000\n",
      "val part1: loss 1.593264\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 20 / 100\n",
      "train part1: batch 0/29, loss 1.375, top-1 accuracy 58.000, top-5 accuracy 90.000\n",
      "train part1: loss 1.013524\n",
      "val part1: batch 0/59, loss 2.251, top-1 accuracy 26.000, top-5 accuracy 74.000\n",
      "val part1: loss 1.565414\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 21 / 100\n",
      "train part1: batch 0/29, loss 0.838, top-1 accuracy 72.000, top-5 accuracy 98.000\n",
      "train part1: loss 1.007995\n",
      "val part1: batch 0/59, loss 1.984, top-1 accuracy 32.000, top-5 accuracy 82.000\n",
      "val part1: loss 1.619596\n",
      "Checkpoint saved\n",
      "part1 Epoch 22 / 100\n",
      "train part1: batch 0/29, loss 0.810, top-1 accuracy 78.000, top-5 accuracy 94.000\n",
      "train part1: loss 0.996560\n",
      "val part1: batch 0/59, loss 2.944, top-1 accuracy 20.000, top-5 accuracy 70.000\n",
      "val part1: loss 1.741710\n",
      "Checkpoint saved\n",
      "part1 Epoch 23 / 100\n",
      "train part1: batch 0/29, loss 0.727, top-1 accuracy 78.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.995217\n",
      "val part1: batch 0/59, loss 2.453, top-1 accuracy 24.000, top-5 accuracy 74.000\n",
      "val part1: loss 1.648032\n",
      "Checkpoint saved\n",
      "part1 Epoch 24 / 100\n",
      "train part1: batch 0/29, loss 1.023, top-1 accuracy 70.000, top-5 accuracy 94.000\n",
      "train part1: loss 0.928896\n",
      "val part1: batch 0/59, loss 3.217, top-1 accuracy 24.000, top-5 accuracy 64.000\n",
      "val part1: loss 1.625620\n",
      "Checkpoint saved\n",
      "part1 Epoch 25 / 100\n",
      "train part1: batch 0/29, loss 0.638, top-1 accuracy 80.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.938332\n",
      "val part1: batch 0/59, loss 2.225, top-1 accuracy 24.000, top-5 accuracy 80.000\n",
      "val part1: loss 1.747911\n",
      "Checkpoint saved\n",
      "part1 Epoch 26 / 100\n",
      "train part1: batch 0/29, loss 0.802, top-1 accuracy 74.000, top-5 accuracy 96.000\n",
      "train part1: loss 0.848064\n",
      "val part1: batch 0/59, loss 2.535, top-1 accuracy 24.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.717303\n",
      "Checkpoint saved\n",
      "part1 Epoch 27 / 100\n",
      "train part1: batch 0/29, loss 1.425, top-1 accuracy 64.000, top-5 accuracy 94.000\n",
      "train part1: loss 0.889780\n",
      "val part1: batch 0/59, loss 2.724, top-1 accuracy 28.000, top-5 accuracy 70.000\n",
      "val part1: loss 1.731703\n",
      "Checkpoint saved\n",
      "part1 Epoch 28 / 100\n",
      "train part1: batch 0/29, loss 0.735, top-1 accuracy 70.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.880040\n",
      "val part1: batch 0/59, loss 2.354, top-1 accuracy 32.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.740465\n",
      "Checkpoint saved\n",
      "part1 Epoch 29 / 100\n",
      "train part1: batch 0/29, loss 0.840, top-1 accuracy 66.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.840331\n",
      "val part1: batch 0/59, loss 3.545, top-1 accuracy 14.000, top-5 accuracy 68.000\n",
      "val part1: loss 2.094114\n",
      "Checkpoint saved\n",
      "part1 Epoch 30 / 100\n",
      "train part1: batch 0/29, loss 0.860, top-1 accuracy 72.000, top-5 accuracy 96.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train part1: loss 0.884962\n",
      "val part1: batch 0/59, loss 2.724, top-1 accuracy 20.000, top-5 accuracy 74.000\n",
      "val part1: loss 1.711414\n",
      "Checkpoint saved\n",
      "part1 Epoch 31 / 100\n",
      "train part1: batch 0/29, loss 1.090, top-1 accuracy 70.000, top-5 accuracy 94.000\n",
      "train part1: loss 0.794024\n",
      "val part1: batch 0/59, loss 3.084, top-1 accuracy 22.000, top-5 accuracy 72.000\n",
      "val part1: loss 1.737564\n",
      "Checkpoint saved\n",
      "part1 Epoch 32 / 100\n",
      "train part1: batch 0/29, loss 0.531, top-1 accuracy 84.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.732729\n",
      "val part1: batch 0/59, loss 3.414, top-1 accuracy 18.000, top-5 accuracy 66.000\n",
      "val part1: loss 1.736860\n",
      "Checkpoint saved\n",
      "part1 Epoch 33 / 100\n",
      "train part1: batch 0/29, loss 0.691, top-1 accuracy 82.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.819520\n",
      "val part1: batch 0/59, loss 3.040, top-1 accuracy 22.000, top-5 accuracy 68.000\n",
      "val part1: loss 1.720591\n",
      "Checkpoint saved\n",
      "part1 Epoch 34 / 100\n",
      "train part1: batch 0/29, loss 0.432, top-1 accuracy 86.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.750807\n",
      "val part1: batch 0/59, loss 3.405, top-1 accuracy 22.000, top-5 accuracy 68.000\n",
      "val part1: loss 1.859342\n",
      "Checkpoint saved\n",
      "part1 Epoch 35 / 100\n",
      "train part1: batch 0/29, loss 0.593, top-1 accuracy 82.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.773339\n",
      "val part1: batch 0/59, loss 3.118, top-1 accuracy 16.000, top-5 accuracy 68.000\n",
      "val part1: loss 1.848862\n",
      "Checkpoint saved\n",
      "part1 Epoch 36 / 100\n",
      "train part1: batch 0/29, loss 0.559, top-1 accuracy 82.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.792149\n",
      "val part1: batch 0/59, loss 2.960, top-1 accuracy 26.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.779061\n",
      "Checkpoint saved\n",
      "part1 Epoch 37 / 100\n",
      "train part1: batch 0/29, loss 0.871, top-1 accuracy 72.000, top-5 accuracy 96.000\n",
      "train part1: loss 0.733120\n",
      "val part1: batch 0/59, loss 3.412, top-1 accuracy 20.000, top-5 accuracy 66.000\n",
      "val part1: loss 1.838609\n",
      "Checkpoint saved\n",
      "part1 Epoch 38 / 100\n",
      "train part1: batch 0/29, loss 0.597, top-1 accuracy 76.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.692938\n",
      "val part1: batch 0/59, loss 2.812, top-1 accuracy 24.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.711833\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 39 / 100\n",
      "train part1: batch 0/29, loss 0.800, top-1 accuracy 66.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.637282\n",
      "val part1: batch 0/59, loss 3.511, top-1 accuracy 20.000, top-5 accuracy 68.000\n",
      "val part1: loss 1.889398\n",
      "Checkpoint saved\n",
      "part1 Epoch 40 / 100\n",
      "train part1: batch 0/29, loss 0.385, top-1 accuracy 86.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.677203\n",
      "val part1: batch 0/59, loss 2.904, top-1 accuracy 24.000, top-5 accuracy 82.000\n",
      "val part1: loss 1.807365\n",
      "Checkpoint saved\n",
      "part1 Epoch 41 / 100\n",
      "train part1: batch 0/29, loss 0.672, top-1 accuracy 68.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.663121\n",
      "val part1: batch 0/59, loss 2.949, top-1 accuracy 28.000, top-5 accuracy 86.000\n",
      "val part1: loss 1.828260\n",
      "Checkpoint saved\n",
      "part1 Epoch 42 / 100\n",
      "train part1: batch 0/29, loss 0.781, top-1 accuracy 80.000, top-5 accuracy 96.000\n",
      "train part1: loss 0.654081\n",
      "val part1: batch 0/59, loss 2.979, top-1 accuracy 28.000, top-5 accuracy 80.000\n",
      "val part1: loss 1.895758\n",
      "Checkpoint saved\n",
      "part1 Epoch 43 / 100\n",
      "train part1: batch 0/29, loss 0.678, top-1 accuracy 76.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.649869\n",
      "val part1: batch 0/59, loss 3.403, top-1 accuracy 24.000, top-5 accuracy 66.000\n",
      "val part1: loss 2.046286\n",
      "Checkpoint saved\n",
      "part1 Epoch 44 / 100\n",
      "train part1: batch 0/29, loss 0.654, top-1 accuracy 82.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.615660\n",
      "val part1: batch 0/59, loss 3.178, top-1 accuracy 26.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.936767\n",
      "Checkpoint saved\n",
      "part1 Epoch 45 / 100\n",
      "train part1: batch 0/29, loss 0.535, top-1 accuracy 80.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.638837\n",
      "val part1: batch 0/59, loss 3.503, top-1 accuracy 20.000, top-5 accuracy 70.000\n",
      "val part1: loss 1.747993\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 46 / 100\n",
      "train part1: batch 0/29, loss 0.424, top-1 accuracy 88.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.576530\n",
      "val part1: batch 0/59, loss 3.418, top-1 accuracy 28.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.802895\n",
      "Checkpoint saved\n",
      "part1 Epoch 47 / 100\n",
      "train part1: batch 0/29, loss 0.326, top-1 accuracy 86.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.639991\n",
      "val part1: batch 0/59, loss 2.986, top-1 accuracy 32.000, top-5 accuracy 82.000\n",
      "val part1: loss 1.853082\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 48 / 100\n",
      "train part1: batch 0/29, loss 0.579, top-1 accuracy 78.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.587345\n",
      "val part1: batch 0/59, loss 2.535, top-1 accuracy 28.000, top-5 accuracy 88.000\n",
      "val part1: loss 2.016346\n",
      "Checkpoint saved\n",
      "part1 Epoch 49 / 100\n",
      "train part1: batch 0/29, loss 0.470, top-1 accuracy 82.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.641519\n",
      "val part1: batch 0/59, loss 4.073, top-1 accuracy 20.000, top-5 accuracy 78.000\n",
      "val part1: loss 2.158201\n",
      "Checkpoint saved\n",
      "part1 Epoch 50 / 100\n",
      "train part1: batch 0/29, loss 0.899, top-1 accuracy 72.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.599045\n",
      "val part1: batch 0/59, loss 3.590, top-1 accuracy 20.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.887258\n",
      "Checkpoint saved\n",
      "part1 Epoch 51 / 100\n",
      "train part1: batch 0/29, loss 0.587, top-1 accuracy 74.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.568143\n",
      "val part1: batch 0/59, loss 4.595, top-1 accuracy 14.000, top-5 accuracy 56.000\n",
      "val part1: loss 1.952283\n",
      "Checkpoint saved\n",
      "part1 Epoch 52 / 100\n",
      "train part1: batch 0/29, loss 0.585, top-1 accuracy 86.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.601615\n",
      "val part1: batch 0/59, loss 3.199, top-1 accuracy 26.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.946499\n",
      "Checkpoint saved\n",
      "part1 Epoch 53 / 100\n",
      "train part1: batch 0/29, loss 0.406, top-1 accuracy 78.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.551252\n",
      "val part1: batch 0/59, loss 3.465, top-1 accuracy 30.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.846707\n",
      "Checkpoint saved\n",
      "part1 Epoch 54 / 100\n",
      "train part1: batch 0/29, loss 0.595, top-1 accuracy 84.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.523332\n",
      "val part1: batch 0/59, loss 3.779, top-1 accuracy 18.000, top-5 accuracy 68.000\n",
      "val part1: loss 2.025954\n",
      "Checkpoint saved\n",
      "part1 Epoch 55 / 100\n",
      "train part1: batch 0/29, loss 0.595, top-1 accuracy 78.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.525928\n",
      "val part1: batch 0/59, loss 3.851, top-1 accuracy 18.000, top-5 accuracy 72.000\n",
      "val part1: loss 2.030163\n",
      "Checkpoint saved\n",
      "part1 Epoch 56 / 100\n",
      "train part1: batch 0/29, loss 0.442, top-1 accuracy 84.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.559693\n",
      "val part1: batch 0/59, loss 3.782, top-1 accuracy 22.000, top-5 accuracy 74.000\n",
      "val part1: loss 2.585613\n",
      "Checkpoint saved\n",
      "part1 Epoch 57 / 100\n",
      "train part1: batch 0/29, loss 0.745, top-1 accuracy 74.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.560900\n",
      "val part1: batch 0/59, loss 3.647, top-1 accuracy 16.000, top-5 accuracy 74.000\n",
      "val part1: loss 2.081461\n",
      "Checkpoint saved\n",
      "part1 Epoch 58 / 100\n",
      "train part1: batch 0/29, loss 0.339, top-1 accuracy 88.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.488511\n",
      "val part1: batch 0/59, loss 3.932, top-1 accuracy 22.000, top-5 accuracy 72.000\n",
      "val part1: loss 1.967714\n",
      "Checkpoint saved\n",
      "part1 Epoch 59 / 100\n",
      "train part1: batch 0/29, loss 0.585, top-1 accuracy 78.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.495856\n",
      "val part1: batch 0/59, loss 3.493, top-1 accuracy 22.000, top-5 accuracy 72.000\n",
      "val part1: loss 2.131619\n",
      "Checkpoint saved\n",
      "part1 Epoch 60 / 100\n",
      "train part1: batch 0/29, loss 0.366, top-1 accuracy 90.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.444885\n",
      "val part1: batch 0/59, loss 3.851, top-1 accuracy 20.000, top-5 accuracy 74.000\n",
      "val part1: loss 1.969364\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 61 / 100\n",
      "train part1: batch 0/29, loss 0.332, top-1 accuracy 80.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.387902\n",
      "val part1: batch 0/59, loss 3.947, top-1 accuracy 20.000, top-5 accuracy 70.000\n",
      "val part1: loss 1.963159\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 62 / 100\n",
      "train part1: batch 0/29, loss 0.313, top-1 accuracy 92.000, top-5 accuracy 100.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train part1: loss 0.359770\n",
      "val part1: batch 0/59, loss 3.850, top-1 accuracy 18.000, top-5 accuracy 68.000\n",
      "val part1: loss 1.919866\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 63 / 100\n",
      "train part1: batch 0/29, loss 0.370, top-1 accuracy 90.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.374457\n",
      "val part1: batch 0/59, loss 3.840, top-1 accuracy 18.000, top-5 accuracy 72.000\n",
      "val part1: loss 1.943298\n",
      "Checkpoint saved\n",
      "part1 Epoch 64 / 100\n",
      "train part1: batch 0/29, loss 0.281, top-1 accuracy 94.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.346458\n",
      "val part1: batch 0/59, loss 3.970, top-1 accuracy 18.000, top-5 accuracy 74.000\n",
      "val part1: loss 1.920551\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 65 / 100\n",
      "train part1: batch 0/29, loss 0.368, top-1 accuracy 90.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.356465\n",
      "val part1: batch 0/59, loss 3.995, top-1 accuracy 20.000, top-5 accuracy 72.000\n",
      "val part1: loss 1.930274\n",
      "Checkpoint saved\n",
      "part1 Epoch 66 / 100\n",
      "train part1: batch 0/29, loss 0.275, top-1 accuracy 92.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.348439\n",
      "val part1: batch 0/59, loss 3.953, top-1 accuracy 16.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.950265\n",
      "Checkpoint saved\n",
      "part1 Epoch 67 / 100\n",
      "train part1: batch 0/29, loss 0.449, top-1 accuracy 86.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.323817\n",
      "val part1: batch 0/59, loss 4.021, top-1 accuracy 18.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.948757\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 68 / 100\n",
      "train part1: batch 0/29, loss 0.571, top-1 accuracy 80.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.351458\n",
      "val part1: batch 0/59, loss 3.928, top-1 accuracy 18.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.926983\n",
      "Checkpoint saved\n",
      "part1 Epoch 69 / 100\n",
      "train part1: batch 0/29, loss 0.328, top-1 accuracy 94.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.315425\n",
      "val part1: batch 0/59, loss 3.864, top-1 accuracy 20.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.955007\n",
      "Checkpoint saved\n",
      "part1 Epoch 70 / 100\n",
      "train part1: batch 0/29, loss 0.215, top-1 accuracy 94.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.305265\n",
      "val part1: batch 0/59, loss 3.656, top-1 accuracy 20.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.970191\n",
      "Checkpoint saved\n",
      "part1 Epoch 71 / 100\n",
      "train part1: batch 0/29, loss 0.331, top-1 accuracy 84.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.325006\n",
      "val part1: batch 0/59, loss 3.779, top-1 accuracy 18.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.943663\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 72 / 100\n",
      "train part1: batch 0/29, loss 0.157, top-1 accuracy 94.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.324622\n",
      "val part1: batch 0/59, loss 3.840, top-1 accuracy 18.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.953053\n",
      "Checkpoint saved\n",
      "part1 Epoch 73 / 100\n",
      "train part1: batch 0/29, loss 0.258, top-1 accuracy 88.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.302243\n",
      "val part1: batch 0/59, loss 3.673, top-1 accuracy 20.000, top-5 accuracy 74.000\n",
      "val part1: loss 1.957688\n",
      "Checkpoint saved\n",
      "part1 Epoch 74 / 100\n",
      "train part1: batch 0/29, loss 0.316, top-1 accuracy 92.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.335710\n",
      "val part1: batch 0/59, loss 3.820, top-1 accuracy 16.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.951142\n",
      "Checkpoint saved\n",
      "part1 Epoch 75 / 100\n",
      "train part1: batch 0/29, loss 0.198, top-1 accuracy 94.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.325209\n",
      "val part1: batch 0/59, loss 3.834, top-1 accuracy 22.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.949440\n",
      "Checkpoint saved\n",
      "part1 Epoch 76 / 100\n",
      "train part1: batch 0/29, loss 0.113, top-1 accuracy 96.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.296354\n",
      "val part1: batch 0/59, loss 4.132, top-1 accuracy 18.000, top-5 accuracy 74.000\n",
      "val part1: loss 1.964350\n",
      "Checkpoint saved\n",
      "part1 Epoch 77 / 100\n",
      "train part1: batch 0/29, loss 0.230, top-1 accuracy 94.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.287885\n",
      "val part1: batch 0/59, loss 3.964, top-1 accuracy 18.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.955163\n",
      "Checkpoint saved\n",
      "part1 Epoch 78 / 100\n",
      "train part1: batch 0/29, loss 0.212, top-1 accuracy 92.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.327251\n",
      "val part1: batch 0/59, loss 3.894, top-1 accuracy 20.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.970125\n",
      "Checkpoint saved\n",
      "part1 Epoch 79 / 100\n",
      "train part1: batch 0/29, loss 0.380, top-1 accuracy 84.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.311631\n",
      "val part1: batch 0/59, loss 3.892, top-1 accuracy 18.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.969769\n",
      "Checkpoint saved\n",
      "part1 Epoch 80 / 100\n",
      "train part1: batch 0/29, loss 0.261, top-1 accuracy 92.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.306680\n",
      "val part1: batch 0/59, loss 3.781, top-1 accuracy 20.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.984393\n",
      "Checkpoint saved\n",
      "part1 Epoch 81 / 100\n",
      "train part1: batch 0/29, loss 0.355, top-1 accuracy 82.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.291364\n",
      "val part1: batch 0/59, loss 3.719, top-1 accuracy 20.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.981909\n",
      "Checkpoint saved\n",
      "part1 Epoch 82 / 100\n",
      "train part1: batch 0/29, loss 0.330, top-1 accuracy 88.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.295986\n",
      "val part1: batch 0/59, loss 3.823, top-1 accuracy 20.000, top-5 accuracy 78.000\n",
      "val part1: loss 1.959703\n",
      "Checkpoint saved\n",
      "BEST TOP1 ACCURACY SO FAR\n",
      "part1 Epoch 83 / 100\n",
      "train part1: batch 0/29, loss 0.422, top-1 accuracy 82.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.273368\n",
      "val part1: batch 0/59, loss 3.895, top-1 accuracy 22.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.976559\n",
      "Checkpoint saved\n",
      "part1 Epoch 84 / 100\n",
      "train part1: batch 0/29, loss 0.172, top-1 accuracy 94.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.301103\n",
      "val part1: batch 0/59, loss 4.091, top-1 accuracy 20.000, top-5 accuracy 78.000\n",
      "val part1: loss 2.032020\n",
      "Checkpoint saved\n",
      "part1 Epoch 85 / 100\n",
      "train part1: batch 0/29, loss 0.206, top-1 accuracy 94.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.272098\n",
      "val part1: batch 0/59, loss 3.924, top-1 accuracy 22.000, top-5 accuracy 76.000\n",
      "val part1: loss 2.020548\n",
      "Checkpoint saved\n",
      "part1 Epoch 86 / 100\n",
      "train part1: batch 0/29, loss 0.363, top-1 accuracy 82.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.311119\n",
      "val part1: batch 0/59, loss 4.124, top-1 accuracy 20.000, top-5 accuracy 76.000\n",
      "val part1: loss 2.043764\n",
      "Checkpoint saved\n",
      "part1 Epoch 87 / 100\n",
      "train part1: batch 0/29, loss 0.356, top-1 accuracy 90.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.303635\n",
      "val part1: batch 0/59, loss 3.936, top-1 accuracy 20.000, top-5 accuracy 78.000\n",
      "val part1: loss 2.001008\n",
      "Checkpoint saved\n",
      "part1 Epoch 88 / 100\n",
      "train part1: batch 0/29, loss 0.302, top-1 accuracy 88.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.262898\n",
      "val part1: batch 0/59, loss 4.154, top-1 accuracy 20.000, top-5 accuracy 76.000\n",
      "val part1: loss 1.999233\n",
      "Checkpoint saved\n",
      "part1 Epoch 89 / 100\n",
      "train part1: batch 0/29, loss 0.220, top-1 accuracy 94.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.255189\n",
      "val part1: batch 0/59, loss 4.042, top-1 accuracy 22.000, top-5 accuracy 78.000\n",
      "val part1: loss 2.040652\n",
      "Checkpoint saved\n",
      "part1 Epoch 90 / 100\n",
      "train part1: batch 0/29, loss 0.288, top-1 accuracy 88.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.261664\n",
      "val part1: batch 0/59, loss 3.905, top-1 accuracy 18.000, top-5 accuracy 74.000\n",
      "val part1: loss 2.035694\n",
      "Checkpoint saved\n",
      "part1 Epoch 91 / 100\n",
      "train part1: batch 0/29, loss 0.217, top-1 accuracy 94.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.284084\n",
      "val part1: batch 0/59, loss 4.147, top-1 accuracy 16.000, top-5 accuracy 78.000\n",
      "val part1: loss 2.031166\n",
      "Checkpoint saved\n",
      "part1 Epoch 92 / 100\n",
      "train part1: batch 0/29, loss 0.227, top-1 accuracy 86.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.252427\n",
      "val part1: batch 0/59, loss 4.096, top-1 accuracy 18.000, top-5 accuracy 78.000\n",
      "val part1: loss 2.042494\n",
      "Checkpoint saved\n",
      "part1 Epoch 93 / 100\n",
      "train part1: batch 0/29, loss 0.372, top-1 accuracy 90.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.282437\n",
      "val part1: batch 0/59, loss 4.173, top-1 accuracy 16.000, top-5 accuracy 78.000\n",
      "val part1: loss 2.063740\n",
      "Checkpoint saved\n",
      "part1 Epoch 94 / 100\n",
      "train part1: batch 0/29, loss 0.360, top-1 accuracy 86.000, top-5 accuracy 100.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train part1: loss 0.277133\n",
      "val part1: batch 0/59, loss 4.127, top-1 accuracy 20.000, top-5 accuracy 78.000\n",
      "val part1: loss 2.057956\n",
      "Checkpoint saved\n",
      "part1 Epoch 95 / 100\n",
      "train part1: batch 0/29, loss 0.137, top-1 accuracy 98.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.278142\n",
      "val part1: batch 0/59, loss 3.918, top-1 accuracy 20.000, top-5 accuracy 78.000\n",
      "val part1: loss 2.061296\n",
      "Checkpoint saved\n",
      "part1 Epoch 96 / 100\n",
      "train part1: batch 0/29, loss 0.241, top-1 accuracy 92.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.287967\n",
      "val part1: batch 0/59, loss 4.091, top-1 accuracy 18.000, top-5 accuracy 78.000\n",
      "val part1: loss 2.072681\n",
      "Checkpoint saved\n",
      "part1 Epoch 97 / 100\n",
      "train part1: batch 0/29, loss 0.223, top-1 accuracy 88.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.255993\n",
      "val part1: batch 0/59, loss 4.057, top-1 accuracy 20.000, top-5 accuracy 78.000\n",
      "val part1: loss 2.060077\n",
      "Checkpoint saved\n",
      "part1 Epoch 98 / 100\n",
      "train part1: batch 0/29, loss 0.179, top-1 accuracy 96.000, top-5 accuracy 100.000\n",
      "train part1: loss 0.259868\n",
      "val part1: batch 0/59, loss 3.772, top-1 accuracy 22.000, top-5 accuracy 80.000\n",
      "val part1: loss 2.085488\n",
      "Checkpoint saved\n",
      "part1 Epoch 99 / 100\n",
      "train part1: batch 0/29, loss 0.339, top-1 accuracy 90.000, top-5 accuracy 98.000\n",
      "train part1: loss 0.260986\n",
      "val part1: batch 0/59, loss 3.928, top-1 accuracy 20.000, top-5 accuracy 80.000\n",
      "val part1: loss 2.070649\n",
      "Checkpoint saved\n",
      "Best top-1 Accuracy = 56.583\n"
     ]
    }
   ],
   "source": [
    "# Train the network!\n",
    "trainer = Trainer(train_dataset, test_dataset, model, loss_function, optimizer, lr_scheduler, params)\n",
    "best_prec1 = trainer.train_val()\n",
    "print('Best top-1 Accuracy = {:4.3f}'.format(best_prec1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you get at least 50% accuracy in this section! If you tried different settings than the ones provided to get 50%, you should modify custom_part1_trainer in student code to return a dictionary with your changed settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Fine-Tuning a Pre-Trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seeds so that results will be reproducible\n",
    "set_seed(0, use_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a network from scratch takes a lof of time. Instead of training from scratch, we can take a pre-trained model and fine tune it for our purposes. This is the goal of Part 2--you will train a pre-trained network, and achieve at least 80% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "input_size = (224, 224)\n",
    "RGB = True\n",
    "base_lr = 1e-3\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.9\n",
    "backprop_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pixel mean and stdev...\n",
      "Batch 0 / 30\n",
      "Batch 20 / 30\n",
      "Done, mean = \n",
      "[0.45611589 0.45611589 0.45611589]\n",
      "std = \n",
      "[0.24786406 0.24786406 0.24786406]\n",
      "Computing pixel mean and stdev...\n",
      "Batch 0 / 60\n",
      "Batch 20 / 60\n",
      "Batch 40 / 60\n",
      "Done, mean = \n",
      "[0.45549639 0.45549639 0.45549639]\n",
      "std = \n",
      "[0.24698076 0.24698076 0.24698076]\n"
     ]
    }
   ],
   "source": [
    "# Create the training and testing datasets.\n",
    "train_dataset, test_dataset = sc.create_datasets(data_path=data_path, input_size=input_size, rgb=RGB)\n",
    "assert test_dataset.classes == train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following block loads a pretrained AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the network model.\n",
    "model = alexnet(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you modify create_part2_model from student code in order to fine-tune AlexNet. As you can see in the docs (https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py) and in the model printout above, AlexNet has 2 parts: 'features', which constists of conv layers that extract feature maps from the image, and 'classifier' which consists of FC layers that classify the features. We want to replace the last Linear layer in model.classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=4096, out_features=15, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = sc.create_part2_model(model, num_classes)\n",
    "if use_GPU:\n",
    "    model = model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create the loss function and the optimizer. Just as with part 1, if you modify any of the setttings to hit the required accuracy, you must modify custom_part2_trainer function to return a dictionary containing your changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the trainer. You can modify custom_part2_trainer in\n",
    "# student_copy.py if you want to try different learning settings.\n",
    "custom_part2_trainer = sc.custom_part2_trainer(model)\n",
    "\n",
    "if custom_part2_trainer is None:\n",
    "    # Create the loss function\n",
    "    # see http://pytorch.org/docs/0.3.0/nn.html#loss-functions for a list of available loss functions\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Since we do not want to optimize the whole network, we must extract a list of parameters of interest that will be\n",
    "    # optimized by the optimizer.\n",
    "    params_to_optimize = []\n",
    "\n",
    "    # List of modules in the network\n",
    "    mods = list(model.features.children()) + list(model.classifier.children())\n",
    "\n",
    "    # Extract parameters from the last `backprop_depth` modules in the network and collect them in\n",
    "    # the params_to_optimize list.\n",
    "    for m in mods[::-1][:backprop_depth]:\n",
    "        params_to_optimize.extend(list(m.parameters()))\n",
    "\n",
    "    # Construct the optimizer    \n",
    "    optimizer = optim.SGD(params=params_to_optimize, lr=base_lr, weight_decay=weight_decay, momentum=momentum)\n",
    "\n",
    "    # Create a scheduler, currently a simple step scheduler, but you can get creative.\n",
    "    # See http://pytorch.org/docs/0.3.0/optim.html#how-to-adjust-learning-rate for various LR schedulers\n",
    "    # and how to use them\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    \n",
    "    params = {'n_epochs': 4, 'batch_size': 10, 'experiment': 'part2'} \n",
    "    \n",
    "else:\n",
    "    if 'loss_function' in custom_part2_trainer:\n",
    "        loss_function = custom_part2_trainer['loss_function']\n",
    "    if 'optimizer' in custom_part2_trainer:\n",
    "        optimizer = custom_part2_trainer['optimizer']\n",
    "    if 'lr_scheduler' in custom_part2_trainer:\n",
    "        lr_scheduler = custom_part2_trainer['lr_scheduler']\n",
    "    if 'params' in custom_part2_trainer:\n",
    "        params = custom_part2_trainer['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to fine tune our network! Just like before, we will start a local server to see the training progress of our network. Open a new terminal and activate the environment for this project. Then run the following command: **python -m visdom.server**. This will start a local server. The terminal output should give out a link like: \"http://localhost:8097\". Open this link in your browser. After you run the following block, visit this link again, and you will be able to see graphs showing the progress of your training! If you do not see any graphs, select Part 2 on the top left bar where is says Environment (only select Part 2, do not check main or Part 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Experiment: part2\n",
      "checkpoint_file: None\n",
      "val_freq: 1\n",
      "resume_optim: True\n",
      "batch_size: 10\n",
      "experiment: part2\n",
      "do_val: True\n",
      "print_freq: 100\n",
      "shuffle: True\n",
      "num_workers: 4\n",
      "n_epochs: 4\n",
      "---------------------------------------\n",
      "<utils.Trainer object at 0x1a26a73e10>\n",
      "part2 Epoch 0 / 4\n",
      "train part2: batch 0/149, loss 2.768, top-1 accuracy 10.000, top-5 accuracy 40.000\n",
      "train part2: batch 100/149, loss 0.931, top-1 accuracy 70.000, top-5 accuracy 100.000\n",
      "train part2: loss 0.912878\n",
      "val part2: batch 0/298, loss 0.610, top-1 accuracy 70.000, top-5 accuracy 100.000\n",
      "val part2: batch 100/298, loss 0.531, top-1 accuracy 90.000, top-5 accuracy 100.000\n",
      "val part2: batch 200/298, loss 0.221, top-1 accuracy 90.000, top-5 accuracy 100.000\n"
     ]
    }
   ],
   "source": [
    "# Train the network!\n",
    "trainer = Trainer(train_dataset, test_dataset, model, loss_function, optimizer, lr_scheduler, params)\n",
    "print(trainer)\n",
    "best_prec1 = trainer.train_val()\n",
    "print('Best top-1 Accuracy = {:4.3f}'.format(best_prec1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expect this code to take around 10 minutes on CPU or 30 seconds on GPU. You should hit 80% accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
